{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd735954",
   "metadata": {},
   "source": [
    "# Assignment 3: Part 1 | Titanic\n",
    "David Thor - Practical Maching Learning and AI\n",
    "(MSDS 422 - Winter 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b4345",
   "metadata": {},
   "source": [
    "## Part 0 - Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8c0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do? This will render HTML content.\n",
    "from IPython.display import HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e823e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the use of 'consensual' package nicknames.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7617c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing Data\n",
    "titanic_trainDat = pd.read_csv('train.csv')\n",
    "titanic_testDat =  pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b03f4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_trainDat.shape\n",
    "titanic_testDat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a84fcd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Survived'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking variables to make sure survivied is the y variable\n",
    "set(titanic_trainDat.columns).difference(set(titanic_testDat.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d835e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are the features in the test data a subset of the train data features?\n",
    "set(titanic_testDat.columns).issubset(set(titanic_trainDat.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c353645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Understanding the data\n",
    "titanic_trainDat.info()\n",
    "titanic_trainDat.head(3)\n",
    "titanic_trainDat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3553fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Isolating numerical and categorical variables for potential use later\n",
    "titanic_categoricals = titanic_trainDat[['Survived','Pclass','Sex',\\\n",
    "                                         'Ticket','Cabin','Embarked']]\n",
    "titanic_numericals = titanic_trainDat[['Age','SibSp','Parch','Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6714a886",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Commented for cleaner PDF export\n",
    "\n",
    "# Understanding data distributions\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#for i in titanic_numericals:\n",
    "    #plt.hist(titanic_numericals[i])\n",
    "    #plt.title(i)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16326cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commeneted for cleaner PDF export\n",
    "\n",
    "## Understanding data distributions of categoricals\n",
    "#for i in titanic_categoricals:\n",
    "    #sns.barplot(titanic_categoricals[i].value_counts().index,\\\n",
    "               #titanic_categoricals[i].value_counts()).set_title(i)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86caa0",
   "metadata": {},
   "source": [
    "## EDA\n",
    "- After some initial analysis of the data, below is my plan.\n",
    "    - Drop unnecessary columns (PassengerID, Name)\n",
    "    - I am also going to drop ticket as I don't think it has any revalence. Data seems rather sporatic.\n",
    "    - I am going to feature engineer Cabin section (letter)\n",
    "    - Going to impute numerical data with either mean/median\n",
    "    - Going to impute most categorical with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8667624e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>687</td>\n",
       "      <td>0.771044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>177</td>\n",
       "      <td>0.198653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  Percentage\n",
       "Cabin          687    0.771044\n",
       "Age            177    0.198653\n",
       "Embarked         2    0.002245\n",
       "PassengerId      0    0.000000\n",
       "Survived         0    0.000000\n",
       "Pclass           0    0.000000\n",
       "Name             0    0.000000\n",
       "Sex              0    0.000000\n",
       "SibSp            0    0.000000\n",
       "Parch            0    0.000000\n",
       "Ticket           0    0.000000\n",
       "Fare             0    0.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = titanic_trainDat.isnull().sum().sort_values(ascending = False)\n",
    "pcg = (total / titanic_trainDat.isnull().count()).sort_values\\\n",
    "(ascending = False)\n",
    "miss_val = pd.concat([total, pcg], axis = 1, keys = ['Total', 'Percentage'])\n",
    "miss_val.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c4fa42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Created a function for easier use later with test data\n",
    "def titanic_eda(df):\n",
    "    df['Cabin']=df['Cabin'].fillna('NA')\n",
    "    #Feature Engineer a new variable with only cabin area(letter)\n",
    "    df['cabinLetter'] = df['Cabin'].str[:1]\n",
    "    df['Embarked']=df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    df['Pclass']=df['Pclass'].fillna(df['Pclass'].mode()[0])\n",
    "    df['Sex']=df['Sex'].fillna(df['Sex'].mode()[0])\n",
    "    df['SibSp']=df['SibSp'].fillna(df['SibSp'].median())\n",
    "    df['Parch']=df['Parch'].fillna(df['Parch'].median())\n",
    "    df['Age']=df['Age'].fillna(df['Age'].median())\n",
    "    df['Fare']=df['Fare'].fillna(df['Fare'].mean())\n",
    "    df.drop(['PassengerId','Ticket','Name','Cabin'],axis=1,inplace=True)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be23b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_trainDat = titanic_eda(titanic_trainDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b06f47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(titanic_trainDat.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3733a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Survived     891 non-null    int64  \n",
      " 1   Pclass       891 non-null    int64  \n",
      " 2   Sex          891 non-null    object \n",
      " 3   Age          891 non-null    float64\n",
      " 4   SibSp        891 non-null    int64  \n",
      " 5   Parch        891 non-null    int64  \n",
      " 6   Fare         891 non-null    float64\n",
      " 7   Embarked     891 non-null    object \n",
      " 8   cabinLetter  891 non-null    object \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_trainDat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9797390",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "- I have selected the appropriate numericals and categoricals to standardize and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1ab55c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('standardized', StandardScaler(),\n",
       "                                 [2, 3, 4, 5]),\n",
       "                                ('oneHotter',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 [0, 1, 6, 7])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Encoding\n",
    "# Col transform specs\n",
    "\n",
    "titanic_ct = ColumnTransformer([('standardized',\\\n",
    "                                 preprocessing.StandardScaler(),[2,3,4,5]),\n",
    "       ('oneHotter', preprocessing.OneHotEncoder\\\n",
    "        (handle_unknown='ignore'),[0,1,6,7])])\n",
    "\n",
    "titanic_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f0eacdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate the target from the variables\n",
    "titanic_y=titanic_trainDat.Survived.to_numpy(copy=True)\n",
    "titanic_X=titanic_trainDat.loc[:,titanic_trainDat.columns!='Survived']\\\n",
    ".to_numpy(copy=True)\n",
    "titanic_X.shape   # size\n",
    "titanic_y.shape   # size\n",
    "#titanic_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "322e48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For easier accuracy calcuations.\n",
    "#Selected this metric for performance measurement\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fdc64a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(757, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(134, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(757,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(134,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random split using a scikit-learn preprocessing method\n",
    "# I selected 85% because I want a small yet reasonable for final_test\n",
    "# 134 is a good 'final exam' size to validate my ensemble against\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(titanic_X, titanic_y, \\\n",
    "        train_size=0.85, random_state=9)\n",
    "\n",
    "Xtrain.shape\n",
    "Xtest.shape\n",
    "ytrain.shape\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc25d2",
   "metadata": {},
   "source": [
    "## Modeling Summary\n",
    "\n",
    "- ### Random Forest\n",
    "    - First off, my base RF model accuracy for the training data was 98%. The base model RF for the test data was 77%\n",
    "    - This indicated that there was some overfitting.\n",
    "    - Secondly, I used RandomizedSearchCV to randomly select hyperparameters for a basis to start hyperparameter tuning. This was randomly testing ~4320 combination of hyperparameter settings.\n",
    "    - The best random parameter model's accuracy score for the training and test data were 87% and 78%, respectively. \n",
    "    - Secondly, I used GridSearchCV to further tune the 'best' hyperparameters from the RandomSearchCV to see if it made a difference.\n",
    "    - The GridSearchCV hyperparameters yield an accuracy score for the training and testing data were 86% and 80%.\n",
    "    - In short, I couldn't get much improvement from my results from tuning the RF model. I thought maybe this was the limitation (due to my EDA, etc.) or RF wasn't just a good model for this dataset. I proceeded to Gradient Boosting.\n",
    "  \n",
    "- ### Gradient Boosting\n",
    "    - Since I spent sometime analyzing some of the parameters for the RF model, I manually selected certain intervals to for my GridSearchCV parameters.\n",
    "    - One key parameter I was sure to test out was the learning rate as this differs from the RF model\n",
    "    - The accuracy from my Gradient Boosting model was 87% for the training data, and 81%\n",
    "    - I was happy with the results as this indicating an improvement in score without overfitting/leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5566323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 10,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# I wanted to look at the possible hyperparatmers to test with\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 10)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f661bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "#After reading/understanding some of the hyperparameters, I was ready to test.\n",
    "#I used RandomizedSearchCV, this will randmoly select different combinations\n",
    "#  of hyper parameters to test\n",
    "#This randomly test out 4320 settings\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in \\\n",
    "                np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c80b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = \\\n",
    "                               random_grid, n_iter = 100, cv = 3, \\\n",
    "                               verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(titanic_ct.fit_transform(Xtrain), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b25674e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 70,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These were the best hyper parameters from the random 4320 settings.\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a366832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Training Data Accuracy:  0.9841479524438573\n",
      "Base Model Final Exam Data Accuracy:  0.7761194029850746\n"
     ]
    }
   ],
   "source": [
    "# Below is a base RF model\n",
    "base_model = RandomForestClassifier(random_state = 42)\n",
    "base_model_fit = base_model.fit(titanic_ct.fit_transform(Xtrain), ytrain)\n",
    "y_pred_base_train = base_model_fit.predict(titanic_ct.transform(Xtrain))\n",
    "base_accuracy_trained_data = accuracy_score(ytrain,y_pred_base_train)\n",
    "print (f'Base Model Training Data Accuracy: ',base_accuracy_trained_data)\n",
    "# It's important to see how this base model compares to hypertuned models\n",
    "y_pred_test_base = base_model_fit.predict(titanic_ct.transform(Xtest))\n",
    "base_accuracy_test_data = accuracy_score(ytest,y_pred_test_base)\n",
    "print (f'Base Model Final Exam Data Accuracy: ', base_accuracy_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0dd2db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Model Training Data Accuracy:  0.869220607661823\n",
      "Best Random Model Final Exam Data Accuracy:  0.7835820895522388\n"
     ]
    }
   ],
   "source": [
    "# I am now fitting the best randomized parameters from earlier.\n",
    "best_random_model = rf_random.best_estimator_\n",
    "best_random_model_fit = \\\n",
    "best_random_model.fit(titanic_ct.fit_transform(Xtrain), ytrain)\n",
    "y_pred_trained_random = best_random_model_fit.predict\\\n",
    "(titanic_ct.transform(Xtrain))\n",
    "accuracy_trained_data_random = accuracy_score(ytrain,\\\n",
    "                                              y_pred_trained_random)\n",
    "print (f'Best Random Model Training Data Accuracy: ', \\\n",
    "       accuracy_trained_data_random)\n",
    "#This will show us the accuracy against the test/final exam data\n",
    "y_pred_test_random = best_random_model_fit.predict(\\\n",
    "                                        titanic_ct.transform(Xtest))\n",
    "accuracy_test_data_random = accuracy_score(ytest,y_pred_test_random)\n",
    "print (f'Best Random Model Final Exam Data Accuracy: ', \\\n",
    "       accuracy_test_data_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc7c510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After analyzing some of the hyper parameters from the model above\n",
    "# I decided to further tune the parameters in hopes to better the model\n",
    "# I had selected a cross-fold of 3 because with limited amount of records(800)\n",
    "# I want to make sure the validation records is sufficient.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'n_estimators': [1000, 1400, 1800, 2200]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86b39fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [3, 4, 5],\n",
       "                         'min_samples_split': [2, 4, 8],\n",
       "                         'n_estimators': [1000, 1400, 1800, 2200]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 1400}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will fit and show the best parameters for the RF model\n",
    "grid_search.fit(titanic_ct.fit_transform(Xtrain), ytrain)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e9fc595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter Model Training Data Accuracy:  0.8586525759577279\n",
      "Best Parameter Model Final Exam Data Accuracy:  0.7985074626865671\n"
     ]
    }
   ],
   "source": [
    "# This will show predict and show us the accuracy of the training/test data.\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid_fit = best_grid.fit(titanic_ct.fit_transform(Xtrain), ytrain)\n",
    "y_pred_best_train = best_grid_fit.predict(titanic_ct.transform(Xtrain))\n",
    "accuracy_trained_data_best = accuracy_score(ytrain,y_pred_best_train)\n",
    "print (f'Best Parameter Model Training Data Accuracy: ', \\\n",
    "       accuracy_trained_data_best)\n",
    "\n",
    "y_pred_best_test = best_grid_fit.predict(titanic_ct.transform(Xtest))\n",
    "accuracy_test_data_best = accuracy_score(ytest,y_pred_best_test)\n",
    "print (f'Best Parameter Model Final Exam Data Accuracy: ', \\\n",
    "       accuracy_test_data_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391d604",
   "metadata": {},
   "source": [
    "### Gradient Boosting Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5caa325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'ccp_alpha': 0.0,\n",
      " 'criterion': 'friedman_mse',\n",
      " 'init': None,\n",
      " 'learning_rate': 0.1,\n",
      " 'loss': 'deviance',\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_iter_no_change': None,\n",
      " 'random_state': 10,\n",
      " 'subsample': 1.0,\n",
      " 'tol': 0.0001,\n",
      " 'validation_fraction': 0.1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "##Gradient Boosting possible parameters to tune\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state = 10)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(gbc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "283bca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of trying the randomsearchCV, I am going to just test parameters\n",
    "# I have an idea which ones to tune.\n",
    "# I selected cross fold of 3 because with only ~700 records, \n",
    "# I want to make sure number of records are sufficient for the validation.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": [2, 4, 8],\n",
    "    \"min_samples_leaf\": [3, 4, 5],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.8, 0.9, 1.0],\n",
    "    \"n_estimators\":[8,10,12]\n",
    "}\n",
    "# Create a based model\n",
    "gbc = GradientBoostingClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = gbc, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b589f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6480 candidates, totalling 19440 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['friedman_mse', 'mae'],\n",
       "                         'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
       "                         'loss': ['deviance'], 'max_depth': [3, 5, 8],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'min_samples_leaf': [3, 4, 5],\n",
       "                         'min_samples_split': [2, 4, 8],\n",
       "                         'n_estimators': [8, 10, 12],\n",
       "                         'subsample': [0.5, 0.8, 0.9, 1.0]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'learning_rate': 0.15,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 12,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Best parameters for the gradient boosted model\n",
    "grid_search.fit(titanic_ct.fit_transform(Xtrain), ytrain)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ae1e1a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GradientBoosting Parameter Model Training Data Accuracy:  0.8665785997357992\n",
      "Best GradientBoosting Parameter Model Final Exam Data Accuracy:  0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "# This will fit, predict and show accuracy for the trainng/test data\n",
    "best_gbc_grid = grid_search.best_estimator_\n",
    "best_gbc_grid_fit = best_gbc_grid.fit(titanic_ct.fit_transform(Xtrain)\\\n",
    "                                      , ytrain)\n",
    "y_pred_gbc_train = best_gbc_grid_fit.predict(titanic_ct.transform(Xtrain))\n",
    "accuracy_trained_data_gbc = accuracy_score(ytrain,y_pred_gbc_train)\n",
    "print (f'Best GradientBoosting Parameter Model Training Data Accuracy: ', \\\n",
    "       accuracy_trained_data_gbc)\n",
    "\n",
    "y_pred_test_gbc = best_gbc_grid_fit.predict(titanic_ct.transform(Xtest))\n",
    "accuracy_test_data_gbc = accuracy_score(ytest,y_pred_test_gbc)\n",
    "print (f'Best GradientBoosting Parameter Model Final Exam Data Accuracy: ', \\\n",
    "       accuracy_test_data_gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6427c875",
   "metadata": {},
   "source": [
    "## Implement/Submission\n",
    "- I have decided to use the gradient boosting model because it had the highest 'test/final exam' accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8877b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_testDat =  pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bdd59d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Called the EDA function above before transformations\n",
    "titanic_testDat = titanic_eda(titanic_testDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f3d848a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(titanic_testDat.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0c3e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_final_exam=titanic_testDat.to_numpy(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6081a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict results from the gradient boosted model\n",
    "y_pred = best_gbc_grid_fit.predict(titanic_ct.transform(titanic_final_exam))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f8b5ffe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((418,), (418, 1))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "Regresult = pd.DataFrame(y_pred, columns=['Survived']) \n",
    "df_test['PassengerId'].shape, Regresult.shape \n",
    "test_t = pd.DataFrame(df_test[\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82ad0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.concat([test_t, Regresult ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "164753ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "551d6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('Assignment3-Titanic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
